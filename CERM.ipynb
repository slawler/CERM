{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Maps from NYSDEC Permit Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from GeoCodes import *\n",
    "% matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---Read in data to begin analysis\n",
    "\n",
    "#---Permit data\n",
    "f = r'permit_intersect.txt'\n",
    "data = pd.read_csv(f, sep = ',')\n",
    "\n",
    "#---Flow data\n",
    "f_flow = r'B_NormalFlows_int.txt'\n",
    "flow_data = pd.read_csv(f_flow, sep = '\\t')\n",
    "\n",
    "#---Structure data\n",
    "huc12 = r'hucs_bridges.txt'\n",
    "huc12_data = pd.read_csv(huc12, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-- Count Permits by type from list:\n",
    "'''\n",
    "DA = Dams and Impoundments; \n",
    "DO = Docks and Moorings; \n",
    "EF = Excavation and Fill in Navigable Waters; \n",
    "SD = Stream Disturbance of Protected Stream; \n",
    "WQ = Water Quality Certification\n",
    "'''\n",
    "\n",
    "p_types = data['DEC_Jurisd'].unique()\n",
    "p_total = 0 #--Added as a check to make sure the numbers make sense \n",
    "\n",
    "for p in p_types:\n",
    "    permits = (data['DEC_Jurisd']== p).sum()\n",
    "    #print(p, permits)\n",
    "    p_total += permits\n",
    "\n",
    "#print('\\nTotal Permits = ', p_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--Select subset of permits: Stream Disturbance only\n",
    "\n",
    "df_SD = data[data['DEC_Jurisd']== 'SD']\n",
    "\n",
    "#--Get a count of permits by 'Project' (Batch_Numb field) \n",
    "b_types = df_SD['Batch_Numb'].unique() \n",
    "\n",
    "print('Stream Disturbance of Protected Stream: ', len(df_SD), 'records', len(b_types),'Projects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-- Get a count of permits by 'HUC 12'\n",
    "\n",
    "df_HUC = df_SD.groupby('HUC_12').count()\n",
    "\n",
    "b_types = df_SD['Batch_Numb'].unique()\n",
    "\n",
    "#-- Rank the HUC 12's by number of permits \n",
    "\n",
    "df_HUC_sorted = df_HUC.sort_values(by = ['Batch_Numb'], ascending=False)\n",
    "\n",
    "print('Stream Disturbance of Protected Stream: ', len(df_HUC), 'HUCs', len(b_types),'Projects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select fields from the Permit dataset to include in a map\n",
    "\n",
    "usecols = ['x','y','Short_Proj','owner'] #--all columns after x,y used in map's Pop-up\n",
    "\n",
    "data_popup = usecols[2:len(usecols)] \n",
    "\n",
    "data[usecols].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-- Merge datasets\n",
    "\n",
    "flow_data[['BIN']] = flow_data[['BIN']].astype(str)\n",
    "huc12_data[['BIN']] = huc12_data[['BIN']].astype(str)\n",
    "\n",
    "df_total = pd.merge(flow_data,huc12_data, on = 'BIN', how = 'outer')\n",
    "df_total.head()\n",
    "flow_data.head()\n",
    "huc12_data.head()\n",
    "#df_total.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select fields from the Permit dataset to include in a map\n",
    "\n",
    "usecols2 = ['x','y','BIN','Q100', 'HUC_12'] #--all columns after x,y used in map's Pop-up\n",
    "\n",
    "data_popup2 = usecols2[2:len(usecols2)] \n",
    "\n",
    "df_total[usecols2].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field = 'HUC_12'\n",
    "\n",
    "item = 20200060905\n",
    "\n",
    "\n",
    "df = data.loc[data[field] == item]\n",
    "df2 = df_total.loc[df_total[field] == item]\n",
    "xbar = df['x'].mean()\n",
    "ybar = df['y'].mean()\n",
    "geoj =df_to_geojson(df, data_popup, lat= 'y', lon='x')\n",
    "geoj2 =df_to_geojson(df2, data_popup2, lat= 'y', lon='x')\n",
    "\n",
    "newmap = '{}_{}.html'.format(field,str(item))\n",
    "map_template = 'map_template.html'\n",
    "\n",
    "mapit(newmap,geoj,geoj2,xbar,ybar,map_template)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
